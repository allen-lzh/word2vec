{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此函数作用是对初始语料进行分词处理后，作为训练模型的语料\n",
    "def cut_txt(old_file):\n",
    "    import jieba\n",
    "    global cut_file     # 分词之后保存的文件名\n",
    "    cut_file = old_file + '_cut.txt'\n",
    "\n",
    "    try:\n",
    "        fi = open(old_file, 'r', encoding='utf-8')\n",
    "    except BaseException as e:  # 因BaseException是所有错误的基类，用它可以获得所有错误类型\n",
    "        print(Exception, \":\", e)    # 追踪错误详细信息\n",
    "\n",
    "    text = fi.read()  # 获取文本内容\n",
    "    # jieba.load_userdict(“userDict.txt”) 加载用户自定义词典\n",
    "    new_text = jieba.cut(text, cut_all=False)  # 精确模式\n",
    "    str_out = ' '.join(new_text).replace('，', '').replace('。', '').replace('？', '').replace('！', '') \\\n",
    "        .replace('“', '').replace('”', '').replace('：', '').replace('…', '').replace('（', '').replace('）', '') \\\n",
    "        .replace('—', '').replace('《', '').replace('》', '').replace('、', '').replace('‘', '') \\\n",
    "        .replace('’', '')     # 去掉标点符号\n",
    "    fo = open(cut_file, 'w', encoding='utf-8')\n",
    "    fo.write(str_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(train_file_name, save_model_file):  # model_file_name为训练语料的路径,save_model为保存模型名\n",
    "    from gensim.models import word2vec\n",
    "    import gensim\n",
    "    import logging\n",
    "    # 模型训练，生成词向量\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    sentences = word2vec.Text8Corpus(train_file_name)  # 加载语料\n",
    "    model = gensim.models.Word2Vec(sentences, size=200,iter=20)  # 训练skip-gram模型; 默认window=5\n",
    "    model.save(save_model_file)\n",
    "    model.wv.save_word2vec_format(save_model_name + \".bin\", binary=True)   # 以二进制类型保存模型以便重用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-07 18:44:12,017 : INFO : collecting all words and their counts\n",
      "2019-04-07 18:44:12,020 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-04-07 18:44:12,254 : INFO : collected 45115 word types from a corpus of 476041 raw words and 48 sentences\n",
      "2019-04-07 18:44:12,254 : INFO : Loading a fresh vocabulary\n",
      "2019-04-07 18:44:12,310 : INFO : effective_min_count=5 retains 10315 unique words (22% of original 45115, drops 34800)\n",
      "2019-04-07 18:44:12,311 : INFO : effective_min_count=5 leaves 421126 word corpus (88% of original 476041, drops 54915)\n",
      "2019-04-07 18:44:12,357 : INFO : deleting the raw counts dictionary of 45115 items\n",
      "2019-04-07 18:44:12,361 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2019-04-07 18:44:12,366 : INFO : downsampling leaves estimated 357491 word corpus (84.9% of prior 421126)\n",
      "2019-04-07 18:44:12,406 : INFO : estimated required memory for 10315 words and 200 dimensions: 21661500 bytes\n",
      "2019-04-07 18:44:12,407 : INFO : resetting layer weights\n",
      "2019-04-07 18:44:12,573 : INFO : training model with 3 workers on 10315 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-04-07 18:44:13,279 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-07 18:44:13,293 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:13,296 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:13,299 : INFO : EPOCH - 1 : training on 476041 raw words (357552 effective words) took 0.7s, 494884 effective words/s\n",
      "2019-04-07 18:44:13,965 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-07 18:44:13,977 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:13,984 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:13,987 : INFO : EPOCH - 2 : training on 476041 raw words (357575 effective words) took 0.7s, 524715 effective words/s\n",
      "2019-04-07 18:44:14,673 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-07 18:44:14,682 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:14,689 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:14,693 : INFO : EPOCH - 3 : training on 476041 raw words (357425 effective words) took 0.7s, 510495 effective words/s\n",
      "2019-04-07 18:44:15,386 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-07 18:44:15,401 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:15,409 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:15,411 : INFO : EPOCH - 4 : training on 476041 raw words (357210 effective words) took 0.7s, 502696 effective words/s\n",
      "2019-04-07 18:44:16,304 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-07 18:44:16,314 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:16,325 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:16,329 : INFO : EPOCH - 5 : training on 476041 raw words (357297 effective words) took 0.9s, 391364 effective words/s\n",
      "2019-04-07 18:44:17,022 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-07 18:44:17,036 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:17,050 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:17,053 : INFO : EPOCH - 6 : training on 476041 raw words (357617 effective words) took 0.7s, 498664 effective words/s\n",
      "2019-04-07 18:44:17,749 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-07 18:44:17,757 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:17,760 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:17,761 : INFO : EPOCH - 7 : training on 476041 raw words (357213 effective words) took 0.7s, 507417 effective words/s\n",
      "2019-04-07 18:44:18,456 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-07 18:44:18,472 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:18,474 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:18,476 : INFO : EPOCH - 8 : training on 476041 raw words (357323 effective words) took 0.7s, 502413 effective words/s\n",
      "2019-04-07 18:44:19,268 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-07 18:44:19,274 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:19,287 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:19,291 : INFO : EPOCH - 9 : training on 476041 raw words (357457 effective words) took 0.8s, 442144 effective words/s\n",
      "2019-04-07 18:44:19,924 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-07 18:44:19,934 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:19,937 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:19,939 : INFO : EPOCH - 10 : training on 476041 raw words (357448 effective words) took 0.6s, 560609 effective words/s\n",
      "2019-04-07 18:44:20,598 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-07 18:44:20,613 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:20,615 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:20,617 : INFO : EPOCH - 11 : training on 476041 raw words (357360 effective words) took 0.7s, 532008 effective words/s\n",
      "2019-04-07 18:44:21,322 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-07 18:44:21,329 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:21,334 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:21,336 : INFO : EPOCH - 12 : training on 476041 raw words (357592 effective words) took 0.7s, 505533 effective words/s\n",
      "2019-04-07 18:44:22,110 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-07 18:44:22,126 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:22,128 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:22,130 : INFO : EPOCH - 13 : training on 476041 raw words (357491 effective words) took 0.8s, 452734 effective words/s\n",
      "2019-04-07 18:44:22,809 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-07 18:44:22,823 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:22,825 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:22,826 : INFO : EPOCH - 14 : training on 476041 raw words (357512 effective words) took 0.7s, 521542 effective words/s\n",
      "2019-04-07 18:44:23,569 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-07 18:44:23,577 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:23,585 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:23,586 : INFO : EPOCH - 15 : training on 476041 raw words (357595 effective words) took 0.8s, 474478 effective words/s\n",
      "2019-04-07 18:44:24,234 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-07 18:44:24,245 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:24,249 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:24,250 : INFO : EPOCH - 16 : training on 476041 raw words (357808 effective words) took 0.7s, 541210 effective words/s\n",
      "2019-04-07 18:44:24,928 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-07 18:44:24,942 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:24,943 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:24,944 : INFO : EPOCH - 17 : training on 476041 raw words (357464 effective words) took 0.7s, 518185 effective words/s\n",
      "2019-04-07 18:44:25,618 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-07 18:44:25,629 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:25,632 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:25,634 : INFO : EPOCH - 18 : training on 476041 raw words (357505 effective words) took 0.7s, 529209 effective words/s\n",
      "2019-04-07 18:44:26,297 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-07 18:44:26,301 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:26,305 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:26,306 : INFO : EPOCH - 19 : training on 476041 raw words (357551 effective words) took 0.7s, 535727 effective words/s\n",
      "2019-04-07 18:44:26,968 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-07 18:44:26,982 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-07 18:44:26,986 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-07 18:44:26,988 : INFO : EPOCH - 20 : training on 476041 raw words (357279 effective words) took 0.7s, 528128 effective words/s\n",
      "2019-04-07 18:44:26,991 : INFO : training on a 9520820 raw words (7149274 effective words) took 14.4s, 495877 effective words/s\n",
      "2019-04-07 18:44:26,994 : INFO : saving Word2Vec object under 倚天屠龙记.model, separately None\n",
      "2019-04-07 18:44:26,995 : INFO : not storing attribute vectors_norm\n",
      "2019-04-07 18:44:26,996 : INFO : not storing attribute cum_table\n",
      "2019-04-07 18:44:27,208 : INFO : saved 倚天屠龙记.model\n",
      "2019-04-07 18:44:27,209 : INFO : storing 10315x200 projection weights into 倚天屠龙记.model.bin\n",
      "2019-04-07 18:44:27,284 : INFO : loading Word2Vec object from 倚天屠龙记.model\n",
      "2019-04-07 18:44:27,465 : INFO : loading wv recursively from 倚天屠龙记.model.wv.* with mmap=None\n",
      "2019-04-07 18:44:27,466 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-04-07 18:44:27,467 : INFO : loading vocabulary recursively from 倚天屠龙记.model.vocabulary.* with mmap=None\n",
      "2019-04-07 18:44:27,468 : INFO : loading trainables recursively from 倚天屠龙记.model.trainables.* with mmap=None\n",
      "2019-04-07 18:44:27,469 : INFO : setting ignored attribute cum_table to None\n",
      "2019-04-07 18:44:27,469 : INFO : loaded 倚天屠龙记.model\n",
      "C:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "C:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "2019-04-07 18:44:27,508 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "赵敏和韦一笑的相似度为： 0.4054979\n",
      "-------------------------------\n",
      "\n",
      "和张三丰最相关的词有：\n",
      "\n",
      "俞莲舟 0.6827965378761292\n",
      "太师父 0.6131824254989624\n",
      "宋远桥 0.577965259552002\n",
      "觉远 0.5635546445846558\n",
      "张真人 0.5622043609619141\n",
      "师父 0.562029242515564\n",
      "宋少侠 0.5554066896438599\n",
      "俞岱岩 0.5527279376983643\n",
      "赵小姐 0.5483282804489136\n",
      "宋青书 0.5453828573226929\n",
      "-------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "import os\n",
    "import gensim\n",
    "\n",
    "# if not os.path.exists(cut_file):    # 判断文件是否存在，参考：https://www.cnblogs.com/jhao/p/7243043.html\n",
    "cut_txt('倚天屠龙记.txt')  # 须注意文件必须先另存为utf-8编码格式\n",
    "\n",
    "save_model_name = '倚天屠龙记.model'\n",
    "if not os.path.exists(save_model_name):     # 判断文件是否存在\n",
    "    model_train(cut_file, save_model_name)\n",
    "else:\n",
    "    print('此训练模型已经存在，不用再次训练')\n",
    "\n",
    "# 加载已训练好的模型\n",
    "model_1 = word2vec.Word2Vec.load(save_model_name)\n",
    "# 计算两个词的相似度/相关程度\n",
    "y1 = model_1.similarity(\"赵敏\", \"韦一笑\")\n",
    "print(u\"赵敏和韦一笑的相似度为：\", y1)\n",
    "print(\"-------------------------------\\n\")\n",
    "\n",
    "# 计算某个词的相关词列表\n",
    "y2 = model_1.most_similar(\"张三丰\", topn=10)  # 10个最相关的\n",
    "print(u\"和张三丰最相关的词有：\\n\")\n",
    "for item in y2:\n",
    "    print(item[0], item[1])\n",
    "print(\"-------------------------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
